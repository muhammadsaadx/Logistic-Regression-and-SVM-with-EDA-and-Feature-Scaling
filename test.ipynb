{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = nan\n",
      "Epoch 100: Loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Train the SVM model\u001b[39;00m\n\u001b[32m     97\u001b[39m svm = SVM(learning_rate=\u001b[32m0.001\u001b[39m, lambda_param=\u001b[32m0.01\u001b[39m, epochs=\u001b[32m2000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43msvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m    101\u001b[39m predictions = svm.predict(X)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mSVM.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.epochs):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, x_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         condition = y[idx] * (\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.bias) >= \u001b[32m1\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m condition:\n\u001b[32m     79\u001b[39m             \u001b[38;5;28mself\u001b[39m.weights -= \u001b[38;5;28mself\u001b[39m.learning_rate * (\u001b[32m2\u001b[39m * \u001b[38;5;28mself\u001b[39m.lambda_param * \u001b[38;5;28mself\u001b[39m.weights)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"adult.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = [feature for feature in data.columns if data[feature].dtypes != \"O\"]\n",
    "categorical_features = [feature for feature in data.columns if data[feature].dtypes == \"O\"]\n",
    "\n",
    "# Apply log transformation to numerical features\n",
    "log_scaled_numerical_data = data[numerical_features].apply(np.log1p)\n",
    "\n",
    "# Handle categorical encoding\n",
    "categorical_encoded_data = data[categorical_features].copy()\n",
    "\n",
    "# Ordinal encoding for 'education'\n",
    "education_order = [\n",
    "    \" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \" 11th\", \" 12th\",\n",
    "    \" Some-college\", \" Assoc-acdm\", \" Assoc-voc\", \" HS-grad\", \" Bachelors\",\n",
    "    \" Masters\", \" Prof-school\", \" Doctorate\"\n",
    "]\n",
    "education_map = {val: idx for idx, val in enumerate(education_order)}\n",
    "categorical_encoded_data[\"education\"] = categorical_encoded_data[\"education\"].map(education_map)\n",
    "\n",
    "# Binary encoding for 'sex'\n",
    "categorical_encoded_data[\"sex\"] = categorical_encoded_data[\"sex\"].map({\" Male\": 0, \" Female\": 1})\n",
    "\n",
    "# One-hot encoding for other categorical variables\n",
    "one_hot_features = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"native-country\"]\n",
    "categorical_encoded_data = pd.get_dummies(categorical_encoded_data, columns=one_hot_features, drop_first=True)\n",
    "\n",
    "# Drop NaNs introduced by log transformation\n",
    "log_scaled_numerical_data = log_scaled_numerical_data.dropna()\n",
    "\n",
    "# Align categorical data with numerical data index\n",
    "categorical_encoded_data = categorical_encoded_data.loc[log_scaled_numerical_data.index]\n",
    "\n",
    "# Concatenate numerical and categorical data\n",
    "final_data = pd.concat([log_scaled_numerical_data, categorical_encoded_data], axis=1)\n",
    "\n",
    "# Move target column 'income' to the first column\n",
    "final_data.insert(0, \"income\", final_data.pop(\"income\"))\n",
    "\n",
    "# Convert income to binary (-1 for <=50K, 1 for >50K)\n",
    "final_data[\"income\"] = final_data[\"income\"].map({\" <=50K\": -1, \" >50K\": 1})\n",
    "\n",
    "# Extract features and target variable\n",
    "X = final_data.drop(columns=['income']).values.astype(np.float64)  # Ensure numerical values\n",
    "y = final_data['income'].values.reshape(-1, 1).astype(np.float64)  # Ensure numerical values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts per feature: [    0     0     0     0     0     0 22194 22194     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n",
      "Total NaNs in X: 44388\n"
     ]
    }
   ],
   "source": [
    "nan_columns = np.isnan(X).sum(axis=0)  # Count NaNs per feature\n",
    "print(\"NaN counts per feature:\", nan_columns)\n",
    "print(\"Total NaNs in X:\", np.isnan(X).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
